{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac9fee1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "import torch\n",
    "from x_transformers.x_transformers import XTransformer\n",
    "import torch\n",
    "\n",
    "from run_experiment import *\n",
    "from generate_data import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8621b8e1",
   "metadata": {},
   "source": [
    "## Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b68ae5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "TAG = 'improve_score_2paper_55len'\n",
    "\n",
    "TASK_NAME = 'reverse'\n",
    "TRAIN_SIZE = 100_000\n",
    "VAL_SIZE = 2_000\n",
    "TEST_SIZE = 10_000\n",
    "NUM_INITS = 3\n",
    "\n",
    "\n",
    "NUM_BATCHES = int(2.3e5)\n",
    "BATCH_SIZE = 128\n",
    "LEARNING_RATE = 3e-4\n",
    "GENERATE_EVERY  = 3000\n",
    "NUM_TOKENS = 16 + 2\n",
    "ENC_SEQ_LEN = 55\n",
    "DEC_SEQ_LEN = 55\n",
    "\n",
    "INPUT_LEN = 55"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c7c157e",
   "metadata": {},
   "source": [
    "#### Generate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "369b4839",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class reverse_generator:\n",
    "#     def __init__(self):\n",
    "#         self.src_mask = torch.ones(BATCH_SIZE, ENC_SEQ_LEN).bool().cuda()\n",
    "#         self.tgt_mask = torch.ones(BATCH_SIZE, DEC_SEQ_LEN+1).bool().cuda()\n",
    "    \n",
    "#     def __next__(self):\n",
    "#         X = np.zeros([BATCH_SIZE, ENC_SEQ_LEN]).astype(int)\n",
    "#         y = np.zeros([BATCH_SIZE, DEC_SEQ_LEN+1]).astype(int)\n",
    "#         y[:, 0] = 1\n",
    "#         for i in range(BATCH_SIZE):\n",
    "#             sequence_length = np.random.randint(1, ENC_SEQ_LEN)\n",
    "#             random_sequence = np.random.randint(2, NUM_TOKENS, sequence_length)\n",
    "            \n",
    "#             X[i, :sequence_length] = random_sequence\n",
    "#             y[i, 1:sequence_length + 1] = random_sequence[::-1]\n",
    "\n",
    "\n",
    "#         return torch.tensor(X), torch.tensor(y), self.src_mask, self.tgt_mask   \n",
    "    \n",
    "# generator = reverse_generator()\n",
    "# generate_data(generator, task_name=TASK_NAME, train_size=TRAIN_SIZE, test_size=TEST_SIZE, val_size=VAL_SIZE)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa274e8",
   "metadata": {},
   "source": [
    "#### Gridsearch params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b3b6a2df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'lr': 0.001}, {'lr': 0.0008}, {'lr': 0.0012}, {'lr': 0.0003}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam\n",
    "\n",
    "optim_params = list(ParameterGrid({\n",
    "    'lr': [0.001, 0.0008, 0.0012, 0.0003]\n",
    "}))\n",
    "\n",
    "print(len(optim_params))\n",
    "optim_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e31f2d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_train = data_loader(task_name=f'{TASK_NAME}_train', batch_size=BATCH_SIZE, enc_seq_len=INPUT_LEN, dec_seq_len=DEC_SEQ_LEN)\n",
    "gen_val = data_loader(task_name=f'{TASK_NAME}_val', batch_size=VAL_SIZE, enc_seq_len=INPUT_LEN, dec_seq_len=DEC_SEQ_LEN)\n",
    "gen_test = data_loader(task_name=f'{TASK_NAME}_test', batch_size=TEST_SIZE, enc_seq_len=INPUT_LEN, dec_seq_len=DEC_SEQ_LEN)\n",
    "\n",
    "\n",
    "print_file = f'logs/{TASK_NAME}_{TAG}_cout_logs.txt'\n",
    "t = time.time()\n",
    "\n",
    "param = list(model_parameters)[0]\n",
    "param['enc_depth'], param['enc_heads'] = param['depth,heads']\n",
    "param['dec_depth'], param['dec_heads'] = param['depth,heads']\n",
    "param.pop('depth,heads')\n",
    "\n",
    "with torch.cuda.device(1):\n",
    "    for i, optim_param in enumerate(list(optim_params)):\n",
    "        with open(print_file, 'a') as f:\n",
    "            f.write('\\n\\n' + str(optim_param)+'\\n')\n",
    "        \n",
    "        for init_num in range(1):\n",
    "            model = XTransformer(**param).cuda()\n",
    "\n",
    "            model_name = f\"{TASK_NAME}{INPUT_LEN}_dim{param['dim']}d{param['enc_depth']}h{param['enc_heads']}M{param['enc_num_memory_tokens']}l{param['enc_max_seq_len']}_v{init_num}_{optim_param}\"\n",
    "\n",
    "            optim = optimizer(model.parameters(), **optim_param)\n",
    "            train_validate_model(model, \n",
    "                                train_generator=gen_train, \n",
    "                                val_generator=gen_val, \n",
    "                                optim=optim, \n",
    "                                model_name=model_name, \n",
    "                                dec_seq_len=DEC_SEQ_LEN,\n",
    "                                num_batches=NUM_BATCHES,\n",
    "                                generate_every=GENERATE_EVERY,\n",
    "                                print_file=print_file)\n",
    "            test_model(model, gen_test, model_name, param, TASK_NAME, tag=str(optim_param), dec_seq_len=param['dec_max_seq_len'])\n",
    "            with open(print_file, 'a') as f:\n",
    "                f.write(f'\\nTotal time: {time.time() - t}\\n')\n",
    "            t = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae2fa27",
   "metadata": {},
   "source": [
    "### Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba8ccfca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total runs:  18\n"
     ]
    }
   ],
   "source": [
    "LEARNING_RATE = 0.001\n",
    "\n",
    "model_parameters = ParameterGrid({'dim': [128],\n",
    "    'tie_token_embeds': [True],\n",
    "    'return_tgt_loss': [True],\n",
    "    'enc_num_tokens': [NUM_TOKENS],\n",
    "    'depth,heads': [(2,4)],\n",
    "    'enc_max_seq_len': [55, 28],\n",
    "    'dec_num_tokens': [NUM_TOKENS],\n",
    "    'dec_max_seq_len': [DEC_SEQ_LEN],\n",
    "    'enc_num_memory_tokens': [0, 4, 16]})\n",
    "\n",
    "print('Total runs: ', NUM_INITS * len(model_parameters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25934197",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_train = data_loader(task_name=f'{TASK_NAME}_train', batch_size=BATCH_SIZE, enc_seq_len=INPUT_LEN, dec_seq_len=DEC_SEQ_LEN)\n",
    "gen_val = data_loader(task_name=f'{TASK_NAME}_val', batch_size=VAL_SIZE, enc_seq_len=INPUT_LEN, dec_seq_len=DEC_SEQ_LEN)\n",
    "gen_test = data_loader(task_name=f'{TASK_NAME}_test', batch_size=TEST_SIZE, enc_seq_len=INPUT_LEN, dec_seq_len=DEC_SEQ_LEN)\n",
    "\n",
    "\n",
    "print_file = f'logs/{TASK_NAME}_{TAG}_memory_logs.txt'\n",
    "t = time.time()\n",
    "with torch.cuda.device(1):\n",
    "    for init_num in range(NUM_INITS):\n",
    "        with open(print_file, 'a') as f:\n",
    "            f.write('\\n\\nInit number ' + str(init_num)+'\\n')\n",
    "        for i, param in enumerate(list(model_parameters)):\n",
    "            with open(print_file, 'a') as f:\n",
    "                f.write('\\n\\n' + str(param)+'\\n')\n",
    "            param['enc_depth'], param['enc_heads'] = param['depth,heads']\n",
    "            param['dec_depth'], param['dec_heads'] = param['depth,heads']\n",
    "            param.pop('depth,heads')\n",
    "\n",
    "            with open(print_file, 'a') as f:\n",
    "                f.write(f'{i / len(model_parameters) * 100}%')\n",
    "            model = XTransformer(**param).cuda()\n",
    "\n",
    "            model_name = f\"{TASK_NAME}{INPUT_LEN}_dim{param['dim']}d{param['enc_depth']}h{param['enc_heads']}M{param['enc_num_memory_tokens']}l{param['enc_max_seq_len']}_v{init_num}\"\n",
    "\n",
    "            optim = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "            train_validate_model(model, \n",
    "                                train_generator=gen_train, \n",
    "                                val_generator=gen_val, \n",
    "                                optim=optim, \n",
    "                                model_name=model_name, \n",
    "                                dec_seq_len=DEC_SEQ_LEN,\n",
    "                                num_batches=NUM_BATCHES,\n",
    "                                generate_every=GENERATE_EVERY,\n",
    "                                print_file=print_file)\n",
    "            test_model(model, gen_test, model_name, param, TASK_NAME, tag=TAG, dec_seq_len=param['dec_max_seq_len'])\n",
    "            with open(print_file, 'a') as f:\n",
    "                f.write(f'\\nTotal time: {time.time() - t}\\n')\n",
    "            t = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2423cef8",
   "metadata": {},
   "source": [
    "stopped on: \n",
    "{'dec_max_seq_len': 16, 'dec_num_tokens': 18, 'depth,heads': (2, 4), 'dim': 64, 'enc_max_seq_len': 8, 'enc_num_memory_tokens': 16, 'enc_num_tokens': 18, 'return_tgt_loss': True, 'tie_token_embeds': True}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "429f9fe5",
   "metadata": {},
   "source": [
    "### Test!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1cf136ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dec_max_seq_len': 16, 'dec_num_tokens': 18, 'depth,heads': (1, 1), 'dim': 64, 'enc_max_seq_len': 8, 'enc_num_memory_tokens': 4, 'enc_num_tokens': 18, 'return_tgt_loss': True, 'tie_token_embeds': True}\n",
      "8 4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 12, 64])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init_num = 0\n",
    "\n",
    "gen_train = data_loader(task_name=f'{TASK_NAME}_train', batch_size=BATCH_SIZE, enc_seq_len=ENC_SEQ_LEN, dec_seq_len=DEC_SEQ_LEN)\n",
    "gen_val = data_loader(task_name=f'{TASK_NAME}_val', batch_size=VAL_SIZE, enc_seq_len=ENC_SEQ_LEN, dec_seq_len=DEC_SEQ_LEN)\n",
    "gen_test = data_loader(task_name=f'{TASK_NAME}_test', batch_size=TEST_SIZE, enc_seq_len=ENC_SEQ_LEN, dec_seq_len=DEC_SEQ_LEN)\n",
    "\n",
    "\n",
    "param = list(model_parameters)[5]\n",
    "print(param)\n",
    "param['enc_depth'], param['enc_heads'] = param['depth,heads']\n",
    "param['dec_depth'], param['dec_heads'] = param['depth,heads']\n",
    "param.pop('depth,heads')\n",
    "\n",
    "model = XTransformer(**param).cuda()\n",
    "\n",
    "model_name = f\"{TASK_NAME}_dim{param['dim']}d{param['enc_depth']}h{param['enc_heads']}M{param['enc_num_memory_tokens']}l{param['enc_max_seq_len']}_v{init_num}\"\n",
    "\n",
    "optim = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "src, tgt, _, _ = next(gen_train)\n",
    "\n",
    "print(model.encoder.max_seq_len, model.encoder.num_memory_tokens)\n",
    "model.encoder(torch.cat((src, src)), return_embeddings=True).shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
