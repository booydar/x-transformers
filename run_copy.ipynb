{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28d18da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "import torch\n",
    "from x_transformers.x_transformers import XTransformer\n",
    "import torch\n",
    "\n",
    "from run_experiment import *\n",
    "from generate_data import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "746e6986",
   "metadata": {},
   "source": [
    "## Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1de49706",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total runs:  3\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "TAG = 'improve_score_2paper_55len'\n",
    "\n",
    "TASK_NAME = 'copy'\n",
    "TRAIN_SIZE = 100_000\n",
    "VAL_SIZE = 2_000\n",
    "TEST_SIZE = 10_000\n",
    "NUM_INITS = 3\n",
    "\n",
    "\n",
    "NUM_BATCHES = int(2.3e5)\n",
    "BATCH_SIZE = 64\n",
    "LEARNING_RATE = 3e-4\n",
    "GENERATE_EVERY  = 3000\n",
    "NUM_TOKENS = 16 + 2\n",
    "ENC_SEQ_LEN = 55\n",
    "DEC_SEQ_LEN = 110\n",
    "\n",
    "INPUT_LEN = 55\n",
    "\n",
    "model_parameters = ParameterGrid({'dim': [128],\n",
    "    'tie_token_embeds': [True],\n",
    "    'return_tgt_loss': [True],\n",
    "    'enc_num_tokens': [NUM_TOKENS],\n",
    "    'depth,heads': [(2,4)],\n",
    "    'enc_max_seq_len': [55],\n",
    "    'dec_num_tokens': [NUM_TOKENS],\n",
    "    'dec_max_seq_len': [DEC_SEQ_LEN],\n",
    "    'enc_num_memory_tokens': [0]})\n",
    "\n",
    "print('Total runs: ', NUM_INITS * len(model_parameters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "09c343bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, p in enumerate(model_parameters):\n",
    "#     print(i, p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a87cb25",
   "metadata": {},
   "source": [
    "#### Generate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "31b7097a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class copy_generator:\n",
    "#     def __init__(self):\n",
    "#         self.src_mask = torch.ones(BATCH_SIZE, ENC_SEQ_LEN).bool().cuda()\n",
    "#         self.tgt_mask = torch.ones(BATCH_SIZE, DEC_SEQ_LEN+1).bool().cuda()\n",
    "    \n",
    "#     def __next__(self):\n",
    "#         X = np.zeros([BATCH_SIZE, ENC_SEQ_LEN]).astype(int)\n",
    "#         y = np.zeros([BATCH_SIZE, DEC_SEQ_LEN+1]).astype(int)\n",
    "#         y[:, 0] = 1\n",
    "#         for i in range(BATCH_SIZE):\n",
    "#             sequence_length = np.random.randint(1, ENC_SEQ_LEN)\n",
    "#             random_sequence = np.random.randint(2, NUM_TOKENS, sequence_length)\n",
    "            \n",
    "#             X[i, :sequence_length] = random_sequence\n",
    "#             y[i, 1: 2 * sequence_length + 1] = np.concatenate([random_sequence] * 2)\n",
    "\n",
    "#         return torch.tensor(X), torch.tensor(y), self.src_mask, self.tgt_mask      \n",
    "    \n",
    "# generator = copy_generator()\n",
    "# generate_data(generator, task_name=TASK_NAME, train_size=TRAIN_SIZE, test_size=TEST_SIZE, val_size=VAL_SIZE)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "437ed429",
   "metadata": {},
   "source": [
    "#### Gridesarch params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "54a62cea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam\n",
    "\n",
    "optim_params = list(ParameterGrid({\n",
    "    'lr': [0.001, 0.0008, 0.0012]\n",
    "}))\n",
    "\n",
    "print(len(optim_params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5f70a159",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'lr': 0.001}, {'lr': 0.0008}, {'lr': 0.0012}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optim_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa4babef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gen_train = data_loader(task_name=f'{TASK_NAME}_train', batch_size=BATCH_SIZE, enc_seq_len=INPUT_LEN, dec_seq_len=DEC_SEQ_LEN)\n",
    "# gen_val = data_loader(task_name=f'{TASK_NAME}_val', batch_size=VAL_SIZE, enc_seq_len=INPUT_LEN, dec_seq_len=DEC_SEQ_LEN)\n",
    "# gen_test = data_loader(task_name=f'{TASK_NAME}_test', batch_size=TEST_SIZE, enc_seq_len=INPUT_LEN, dec_seq_len=DEC_SEQ_LEN)\n",
    "\n",
    "\n",
    "# print_file = f'logs/{TASK_NAME}_{TAG}_cout_logs.txt'\n",
    "# t = time.time()\n",
    "\n",
    "# param = list(model_parameters)[0]\n",
    "# param['enc_depth'], param['enc_heads'] = param['depth,heads']\n",
    "# param['dec_depth'], param['dec_heads'] = param['depth,heads']\n",
    "# param.pop('depth,heads')\n",
    "\n",
    "# with torch.cuda.device(0):\n",
    "#     for i, optim_param in enumerate(list(optim_params)):\n",
    "#         with open(print_file, 'a') as f:\n",
    "#             f.write('\\n\\n' + str(optim_param)+'\\n')\n",
    "        \n",
    "#         for init_num in range(1):\n",
    "#             model = XTransformer(**param).cuda()\n",
    "\n",
    "#             model_name = f\"{TASK_NAME}{INPUT_LEN}_dim{param['dim']}d{param['enc_depth']}h{param['enc_heads']}M{param['enc_num_memory_tokens']}l{param['enc_max_seq_len']}_v{init_num}_{optim_param}\"\n",
    "\n",
    "#             optim = optimizer(model.parameters(), **optim_param)\n",
    "#             train_validate_model(model, \n",
    "#                                 train_generator=gen_train, \n",
    "#                                 val_generator=gen_val, \n",
    "#                                 optim=optim, \n",
    "#                                 model_name=model_name, \n",
    "#                                 dec_seq_len=DEC_SEQ_LEN,\n",
    "#                                 num_batches=NUM_BATCHES,\n",
    "#                                 generate_every=GENERATE_EVERY,\n",
    "#                                 print_file=print_file)\n",
    "#             test_model(model, gen_test, model_name, param, TASK_NAME, tag=str(optim_param), dec_seq_len=param['dec_max_seq_len'])\n",
    "#             with open(print_file, 'a') as f:\n",
    "#                 f.write(f'\\nTotal time: {time.time() - t}\\n')\n",
    "#             t = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c118128",
   "metadata": {},
   "source": [
    "### Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7e975a98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total runs:  18\n"
     ]
    }
   ],
   "source": [
    "LEARNING_RATE = 0.001\n",
    "\n",
    "model_parameters = ParameterGrid({'dim': [128],\n",
    "    'tie_token_embeds': [True],\n",
    "    'return_tgt_loss': [True],\n",
    "    'enc_num_tokens': [NUM_TOKENS],\n",
    "    'depth,heads': [(2,4)],\n",
    "    'enc_max_seq_len': [55, 28],\n",
    "    'dec_num_tokens': [NUM_TOKENS],\n",
    "    'dec_max_seq_len': [DEC_SEQ_LEN],\n",
    "    'enc_num_memory_tokens': [0, 4, 16]})\n",
    "\n",
    "print('Total runs: ', NUM_INITS * len(model_parameters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92978633",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Init number  0\n",
      "{'dec_max_seq_len': 110, 'dec_num_tokens': 18, 'depth,heads': (2, 4), 'dim': 128, 'enc_max_seq_len': 55, 'enc_num_memory_tokens': 0, 'enc_num_tokens': 18, 'return_tgt_loss': True, 'tie_token_embeds': True}\n",
      "0.0 %\n"
     ]
    }
   ],
   "source": [
    "gen_train = data_loader(task_name=f'{TASK_NAME}_train', batch_size=BATCH_SIZE, enc_seq_len=INPUT_LEN, dec_seq_len=DEC_SEQ_LEN)\n",
    "gen_val = data_loader(task_name=f'{TASK_NAME}_val', batch_size=VAL_SIZE, enc_seq_len=INPUT_LEN, dec_seq_len=DEC_SEQ_LEN)\n",
    "gen_test = data_loader(task_name=f'{TASK_NAME}_test', batch_size=TEST_SIZE, enc_seq_len=INPUT_LEN, dec_seq_len=DEC_SEQ_LEN)\n",
    "\n",
    "\n",
    "t = time.time()\n",
    "with torch.cuda.device(0):\n",
    "    for init_num in range(NUM_INITS):\n",
    "        print('\\n\\n\\nInit number ', init_num)\n",
    "        for i, param in enumerate(list(model_parameters)):\n",
    "            print(param)\n",
    "            param['enc_depth'], param['enc_heads'] = param['depth,heads']\n",
    "            param['dec_depth'], param['dec_heads'] = param['depth,heads']\n",
    "            param.pop('depth,heads')\n",
    "\n",
    "            print(i / len(model_parameters) * 100, '%')\n",
    "            model = XTransformer(**param).cuda()\n",
    "\n",
    "            model_name = f\"{TASK_NAME}{INPUT_LEN}_dim{param['dim']}d{param['enc_depth']}h{param['enc_heads']}M{param['enc_num_memory_tokens']}l{param['enc_max_seq_len']}_v{init_num}\"\n",
    "\n",
    "            optim = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "            train_validate_model(model, \n",
    "                                train_generator=gen_train, \n",
    "                                val_generator=gen_val, \n",
    "                                optim=optim, \n",
    "                                model_name=model_name, \n",
    "                                dec_seq_len=DEC_SEQ_LEN,\n",
    "                                num_batches=NUM_BATCHES,\n",
    "                                generate_every=GENERATE_EVERY)\n",
    "            test_model(model, gen_test, model_name, param, TASK_NAME, tag=TAG, dec_seq_len=param['dec_max_seq_len'])\n",
    "            print('Total time: ', time.time() - t)\n",
    "            t = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d5fbeb3",
   "metadata": {},
   "source": [
    "stopped on: {'dec_max_seq_len': 32, 'dec_num_tokens': 18, 'depth,heads': (2, 4), 'dim': 64, 'enc_max_seq_len': 16, 'enc_num_memory_tokens': 16, 'enc_num_tokens': 18, 'return_tgt_loss': True, 'tie_token_embeds': True}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "448fca13",
   "metadata": {},
   "source": [
    "### Test!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b09847b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "init_num = 0\n",
    "\n",
    "gen_train = data_loader(task_name=f'{TASK_NAME}_train', batch_size=BATCH_SIZE, enc_seq_len=ENC_SEQ_LEN, dec_seq_len=DEC_SEQ_LEN)\n",
    "gen_val = data_loader(task_name=f'{TASK_NAME}_val', batch_size=VAL_SIZE, enc_seq_len=ENC_SEQ_LEN, dec_seq_len=DEC_SEQ_LEN)\n",
    "gen_test = data_loader(task_name=f'{TASK_NAME}_test', batch_size=TEST_SIZE, enc_seq_len=ENC_SEQ_LEN, dec_seq_len=DEC_SEQ_LEN)\n",
    "\n",
    "\n",
    "param = list(model_parameters)[5]\n",
    "print(param)\n",
    "param['enc_depth'], param['enc_heads'] = param['depth,heads']\n",
    "param['dec_depth'], param['dec_heads'] = param['depth,heads']\n",
    "param.pop('depth,heads')\n",
    "\n",
    "model = XTransformer(**param).cuda()\n",
    "\n",
    "model_name = f\"{TASK_NAME}_dim{param['dim']}d{param['enc_depth']}h{param['enc_heads']}M{param['enc_num_memory_tokens']}l{param['enc_max_seq_len']}_v{init_num}\"\n",
    "\n",
    "optim = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "src, tgt, _, _ = next(gen_train)\n",
    "\n",
    "print(model.encoder.max_seq_len, model.encoder.num_memory_tokens)\n",
    "model.encoder(torch.cat((src, src)), return_embeddings=True).shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
