{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac9fee1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import random\n",
    "import torch\n",
    "from x_transformers.x_transformers import XTransformer\n",
    "import torch\n",
    "\n",
    "from run_experiment import *\n",
    "from generate_data import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8621b8e1",
   "metadata": {},
   "source": [
    "## Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b68ae5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total runs:  3\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "TAG = 'improve_score_2paper'\n",
    "\n",
    "TASK_NAME = 'listops'\n",
    "TRAIN_SIZE = 90_000\n",
    "VAL_SIZE = 5_000\n",
    "TEST_SIZE = 10_000\n",
    "NUM_INITS = 3\n",
    "\n",
    "\n",
    "NUM_BATCHES = int(2.3e5)\n",
    "BATCH_SIZE = 128\n",
    "LEARNING_RATE = 3e-4\n",
    "GENERATE_EVERY  = 5000\n",
    "ENC_NUM_TOKENS = 10+5+2\n",
    "DEC_NUM_TOKENS = 12\n",
    "ENC_SEQ_LEN = 1150\n",
    "DEC_SEQ_LEN = 1\n",
    "\n",
    "INPUT_LEN = 1150\n",
    "\n",
    "model_parameters = ParameterGrid({'dim': [256],\n",
    "    'tie_token_embeds': [True],\n",
    "    'return_tgt_loss': [True],\n",
    "    'enc_num_tokens': [ENC_NUM_TOKENS],\n",
    "    'depth,heads': [(1,1)],\n",
    "    'enc_max_seq_len': [1150],\n",
    "    'dec_num_tokens': [DEC_NUM_TOKENS],\n",
    "    'dec_max_seq_len': [DEC_SEQ_LEN],\n",
    "    'enc_num_memory_tokens': [0]})\n",
    "\n",
    "print('Total runs: ', NUM_INITS * len(model_parameters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2209a8bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, p in enumerate(model_parameters):\n",
    "#     print(i, p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c7c157e",
   "metadata": {},
   "source": [
    "#### Generate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "369b4839",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class listops_generator:\n",
    "#     def __init__(self, max_depth=2):\n",
    "#         self.src_mask = torch.ones(BATCH_SIZE, ENC_SEQ_LEN).bool()\n",
    "#         self.tgt_mask = torch.ones(BATCH_SIZE, DEC_SEQ_LEN+1).bool()\n",
    "#         self.max_depth = max_depth\n",
    "    \n",
    "#     def __next__(self):\n",
    "#         X = np.zeros([BATCH_SIZE, ENC_SEQ_LEN]).astype(int)\n",
    "#         y = np.ones([BATCH_SIZE, 2]).astype(int) * 2\n",
    "#         for i in range(BATCH_SIZE):\n",
    "#             t = generate_tree(self.max_depth)\n",
    "#             tokens, value = to_tokens(t), to_value(t) \n",
    "#             X[i, 0:len(tokens)], y[i, 1:] = tokens, value+2\n",
    "#             del t\n",
    "\n",
    "#         return torch.tensor(X), torch.tensor(y), self.src_mask, self.tgt_mask         \n",
    "\n",
    "\n",
    "# generator = listops_generator()\n",
    "# generate_data(generator, task_name=TASK_NAME, train_size=TRAIN_SIZE, test_size=TEST_SIZE, val_size=VAL_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f30b2624",
   "metadata": {},
   "source": [
    "#### Gridsearch params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bb30acb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'lr': 0.0008, 'momentum': 0.2},\n",
       " {'lr': 0.0008, 'momentum': 0.4},\n",
       " {'lr': 0.0004, 'momentum': 0.2},\n",
       " {'lr': 0.0004, 'momentum': 0.4}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer = torch.optim.SGD\n",
    "\n",
    "optim_params = list(ParameterGrid({\n",
    "    'lr': [0.0008, 0.0004],\n",
    "    'momentum': [0.2, 0.4]\n",
    "}))\n",
    "\n",
    "print(len(optim_params))\n",
    "optim_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "991938af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "\n",
    "# names = ['data/load_listops/load_listops_train_X.npy',\n",
    "#         'data/load_listops/load_listops_train_y.npy',\n",
    "#         'data/load_listops/load_listops_test_X.npy',\n",
    "#         'data/load_listops/load_listops_test_y.npy']\n",
    "\n",
    "# for name in names: \n",
    "#     x = np.load(name).astype(int)\n",
    "#     np.save(name, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d1f2ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_train = data_loader(task_name='load_listops/load_listops_train', batch_size=BATCH_SIZE, enc_seq_len=ENC_SEQ_LEN, dec_seq_len=DEC_SEQ_LEN)\n",
    "gen_val = data_loader(task_name='load_listops/load_listops_test', batch_size=VAL_SIZE, enc_seq_len=ENC_SEQ_LEN, dec_seq_len=DEC_SEQ_LEN)\n",
    "gen_test = data_loader(task_name='load_listops/load_listops_test', batch_size=TEST_SIZE, enc_seq_len=ENC_SEQ_LEN, dec_seq_len=DEC_SEQ_LEN)\n",
    "\n",
    "\n",
    "print_file = f'logs/{TASK_NAME}_{TAG}_cout_logs2.txt'\n",
    "t = time.time()\n",
    "\n",
    "param = list(model_parameters)[0]\n",
    "param['enc_depth'], param['enc_heads'] = param['depth,heads']\n",
    "param['dec_depth'], param['dec_heads'] = param['depth,heads']\n",
    "param.pop('depth,heads')\n",
    "\n",
    "with torch.cuda.device(1):\n",
    "    for i, optim_param in enumerate(list(optim_params)):\n",
    "        with open(print_file, 'a') as f:\n",
    "            f.write('\\n\\n' + str(optim_param)+'\\n')\n",
    "        \n",
    "        for init_num in range(1):\n",
    "            model = XTransformer(**param).cuda()\n",
    "\n",
    "            model_name = f\"{TASK_NAME}{INPUT_LEN}_dim{param['dim']}d{param['enc_depth']}h{param['enc_heads']}M{param['enc_num_memory_tokens']}l{param['enc_max_seq_len']}_v{init_num}_{optim_param}\"\n",
    "\n",
    "            optim = optimizer(model.parameters(), **optim_param)\n",
    "            train_validate_model(model, \n",
    "                                train_generator=gen_train, \n",
    "                                val_generator=gen_val, \n",
    "                                optim=optim, \n",
    "                                model_name=model_name, \n",
    "                                dec_seq_len=DEC_SEQ_LEN,\n",
    "                                num_batches=NUM_BATCHES,\n",
    "                                generate_every=GENERATE_EVERY,\n",
    "                                print_file=print_file)\n",
    "            test_model(model, gen_test, model_name, param, TASK_NAME, tag=str(optim_param), dec_seq_len=param['dec_max_seq_len'])\n",
    "            with open(print_file, 'a') as f:\n",
    "                f.write(f'\\nTotal time: {time.time() - t}\\n')\n",
    "            t = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae2fa27",
   "metadata": {},
   "source": [
    "### Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ef12541b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# s, t, _, _ = next(gen_train)\n",
    "# s[0], t[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "25934197",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Init number  0\n",
      "{'dec_max_seq_len': 1, 'dec_num_tokens': 12, 'depth,heads': (1, 1), 'dim': 256, 'enc_max_seq_len': 1150, 'enc_num_memory_tokens': 0, 'enc_num_tokens': 17, 'return_tgt_loss': True, 'tie_token_embeds': True}\n",
      "0.0 %\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected tensor for argument #1 'indices' to have one of the following scalar types: Long, Int; but got torch.cuda.DoubleTensor instead (while checking arguments for embedding)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_101540/3692831076.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0moptim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mLEARNING_RATE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m             train_validate_model(model, \n\u001b[0m\u001b[1;32m     23\u001b[0m                                 \u001b[0mtrain_generator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgen_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m                                 \u001b[0mval_generator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgen_val\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/x-transformers/run_experiment.py\u001b[0m in \u001b[0;36mtrain_validate_model\u001b[0;34m(model, train_generator, val_generator, optim, model_name, generate_every, dec_seq_len, num_batches, verbose, overfit_stop, print_file)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msrc_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtgt_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/x-transformers/x_transformers/x_transformers.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, src, tgt, src_mask, tgt_mask)\u001b[0m\n\u001b[1;32m    918\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 920\u001b[0;31m         \u001b[0menc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msrc_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    921\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtgt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtgt_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msrc_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    922\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/x-transformers/x_transformers/x_transformers.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, return_embeddings, mask, return_mems, return_attn, mem, mems, **kwargs)\u001b[0m\n\u001b[1;32m    788\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mout_chunk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 790\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoken_emb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    791\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos_emb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    792\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0memb_dropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/sparse.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m         return F.embedding(\n\u001b[0m\u001b[1;32m    159\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m             self.norm_type, self.scale_grad_by_freq, self.sparse)\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   2041\u001b[0m         \u001b[0;31m# remove once script supports set_grad_enabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2042\u001b[0m         \u001b[0m_no_grad_embedding_renorm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2043\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2044\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2045\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected tensor for argument #1 'indices' to have one of the following scalar types: Long, Int; but got torch.cuda.DoubleTensor instead (while checking arguments for embedding)"
     ]
    }
   ],
   "source": [
    "gen_train = data_loader(task_name='load_listops/load_listops_train', batch_size=BATCH_SIZE, enc_seq_len=ENC_SEQ_LEN, dec_seq_len=DEC_SEQ_LEN)\n",
    "gen_val = data_loader(task_name='load_listops/load_listops_test', batch_size=VAL_SIZE, enc_seq_len=ENC_SEQ_LEN, dec_seq_len=DEC_SEQ_LEN)\n",
    "gen_test = data_loader(task_name='load_listops/load_listops_test', batch_size=TEST_SIZE, enc_seq_len=ENC_SEQ_LEN, dec_seq_len=DEC_SEQ_LEN)\n",
    "\n",
    "\n",
    "t = time.time()\n",
    "with torch.cuda.device(1):\n",
    "    for init_num in range(NUM_INITS):\n",
    "        print('\\n\\n\\nInit number ', init_num)\n",
    "        for i, param in enumerate(list(model_parameters)):\n",
    "            print(param)\n",
    "            param['enc_depth'], param['enc_heads'] = param['depth,heads']\n",
    "            param['dec_depth'], param['dec_heads'] = param['depth,heads']\n",
    "            param.pop('depth,heads')\n",
    "\n",
    "            print(i / len(model_parameters) * 100, '%')\n",
    "            model = XTransformer(**param).cuda()\n",
    "\n",
    "            model_name = f\"{TASK_NAME}{INPUT_LEN}_dim{param['dim']}d{param['enc_depth']}h{param['enc_heads']}M{param['enc_num_memory_tokens']}l{param['enc_max_seq_len']}_v{init_num}\"\n",
    "\n",
    "            optim = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "            train_validate_model(model, \n",
    "                                train_generator=gen_train, \n",
    "                                val_generator=gen_val, \n",
    "                                optim=optim, \n",
    "                                model_name=model_name, \n",
    "                                dec_seq_len=DEC_SEQ_LEN,\n",
    "                                num_batches=NUM_BATCHES,\n",
    "                                generate_every=GENERATE_EVERY)\n",
    "            test_model(model, gen_test, model_name, param, TASK_NAME, tag=TAG, dec_seq_len=param['dec_max_seq_len'])\n",
    "            print('Total time: ', time.time() - t)\n",
    "            t = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8888991",
   "metadata": {},
   "source": [
    "### Test!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a53ebdf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dec_max_seq_len': 1, 'dec_num_tokens': 12, 'depth,heads': (1, 1), 'dim': 128, 'enc_max_seq_len': 1150, 'enc_num_memory_tokens': 0, 'enc_num_tokens': 17, 'return_tgt_loss': True, 'tie_token_embeds': True}\n",
      "1150 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 1149, 128])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init_num = 0\n",
    "\n",
    "gen_train = data_loader(task_name='load_listops/load_listops_train', batch_size=BATCH_SIZE, enc_seq_len=ENC_SEQ_LEN, dec_seq_len=DEC_SEQ_LEN)\n",
    "gen_val = data_loader(task_name='load_listops/load_listops_test', batch_size=VAL_SIZE, enc_seq_len=ENC_SEQ_LEN, dec_seq_len=DEC_SEQ_LEN)\n",
    "gen_test = data_loader(task_name='load_listops/load_listops_test', batch_size=TEST_SIZE, enc_seq_len=ENC_SEQ_LEN, dec_seq_len=DEC_SEQ_LEN)\n",
    "\n",
    "\n",
    "param = list(model_parameters)[0]\n",
    "print(param)\n",
    "param['enc_depth'], param['enc_heads'] = param['depth,heads']\n",
    "param['dec_depth'], param['dec_heads'] = param['depth,heads']\n",
    "param.pop('depth,heads')\n",
    "\n",
    "model = XTransformer(**param).cuda()\n",
    "\n",
    "model_name = f\"{TASK_NAME}_dim{param['dim']}d{param['enc_depth']}h{param['enc_heads']}M{param['enc_num_memory_tokens']}l{param['enc_max_seq_len']}_v{init_num}\"\n",
    "\n",
    "optim = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "src, tgt, _, _ = next(gen_train)\n",
    "\n",
    "print(model.encoder.max_seq_len, model.encoder.num_memory_tokens)\n",
    "model.encoder(torch.cat((src, src)), return_embeddings=True).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfcbb572",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7f7c7854",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dec_max_seq_len': 1, 'dec_num_tokens': 12, 'depth,heads': (2, 4), 'dim': 32, 'enc_max_seq_len': 400, 'enc_num_memory_tokens': 128, 'enc_num_tokens': 17, 'return_tgt_loss': True, 'tie_token_embeds': True}\n",
      "400 128\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 528, 32])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init_num = 0\n",
    "\n",
    "gen_train = data_loader(task_name='load_listops/load_listops_train', batch_size=BATCH_SIZE, enc_seq_len=ENC_SEQ_LEN, dec_seq_len=DEC_SEQ_LEN)\n",
    "gen_val = data_loader(task_name='load_listops/load_listops_test', batch_size=VAL_SIZE, enc_seq_len=ENC_SEQ_LEN, dec_seq_len=DEC_SEQ_LEN)\n",
    "gen_test = data_loader(task_name='load_listops/load_listops_test', batch_size=TEST_SIZE, enc_seq_len=ENC_SEQ_LEN, dec_seq_len=DEC_SEQ_LEN)\n",
    "\n",
    "\n",
    "param = list(model_parameters)[-1]\n",
    "print(param)\n",
    "param['enc_depth'], param['enc_heads'] = param['depth,heads']\n",
    "param['dec_depth'], param['dec_heads'] = param['depth,heads']\n",
    "param.pop('depth,heads')\n",
    "\n",
    "model = XTransformer(**param).cuda()\n",
    "\n",
    "model_name = f\"{TASK_NAME}_dim{param['dim']}d{param['enc_depth']}h{param['enc_heads']}M{param['enc_num_memory_tokens']}l{param['enc_max_seq_len']}_v{init_num}\"\n",
    "\n",
    "optim = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "src, tgt, _, _ = next(gen_train)\n",
    "\n",
    "print(model.encoder.max_seq_len, model.encoder.num_memory_tokens)\n",
    "model.encoder(torch.cat((src, src)), return_embeddings=True).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "07da0945",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_test = np.load('data/load_listops/load_listops_test_y.npy').reshape((-1,1))\n",
    "# y_test = np.hstack((np.ones((y_test.shape[0], 1)) * 2, y_test))\n",
    "# np.save('data/load_listops/load_listops_test_y.npy', y_test)\n",
    "\n",
    "# y_train = np.load('data/load_listops/load_listops_train_y.npy').reshape((-1,1))\n",
    "# y_train = np.hstack((np.ones((y_train.shape[0], 1)) * 2, y_train))\n",
    "# np.save('data/load_listops/load_listops_train_y.npy', y_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
