{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac9fee1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "import torch\n",
    "from x_transformers.x_transformers import XTransformer\n",
    "import torch\n",
    "\n",
    "from run_experiment import *\n",
    "from generate_data import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8621b8e1",
   "metadata": {},
   "source": [
    "## Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b68ae5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total runs:  216\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "TAG = '8+30_close2paper'\n",
    "\n",
    "TASK_NAME = 'retrieval_4'\n",
    "TRAIN_SIZE = 100_000\n",
    "VAL_SIZE = 10_000\n",
    "TEST_SIZE = 20_000\n",
    "NUM_INITS = 3\n",
    "\n",
    "\n",
    "NUM_BATCHES = int(1.5e5)\n",
    "BATCH_SIZE = 32\n",
    "LEARNING_RATE = 3e-4\n",
    "GENERATE_EVERY  = NUM_BATCHES // 10\n",
    "ENC_NUM_TOKENS = 26+10+1\n",
    "DEC_NUM_TOKENS = 10+1\n",
    "ENC_SEQ_LEN = 9\n",
    "DEC_SEQ_LEN = 1\n",
    "\n",
    "INPUT_LEN = 9\n",
    "\n",
    "TASK_NAME = 'retrieval_4'\n",
    "model_parameters = ParameterGrid({'dim': [20, 50, 100],\n",
    "    'tie_token_embeds': [True],\n",
    "    'return_tgt_loss': [True],\n",
    "    'enc_num_tokens': [ENC_NUM_TOKENS],\n",
    "    'depth,heads': [(1,1), (2,4)],\n",
    "    'enc_max_seq_len': [3, 5, 9],\n",
    "    'dec_num_tokens': [DEC_NUM_TOKENS],\n",
    "    'dec_max_seq_len': [DEC_SEQ_LEN],\n",
    "    'enc_num_memory_tokens': [0, 2, 4, 8]})\n",
    "\n",
    "# TASK_NAME = 'retrieval_15'\n",
    "# model_parameters = ParameterGrid({'dim': [20, 50, 100],\n",
    "#     'tie_token_embeds': [True],\n",
    "#     'return_tgt_loss': [True],\n",
    "#     'enc_num_tokens': [ENC_NUM_TOKENS],\n",
    "#     'depth,heads': [(1,1), (2,4)],\n",
    "#     'enc_max_seq_len': [5, 10, 15],\n",
    "#     'dec_num_tokens': [DEC_NUM_TOKENS],\n",
    "#     'dec_max_seq_len': [DEC_SEQ_LEN],\n",
    "#     'enc_num_memory_tokens': [0, 2, 4, 8, 16, 32]})\n",
    "\n",
    "print('Total runs: ', NUM_INITS * len(model_parameters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "55df1fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, p in enumerate(model_parameters):\n",
    "#     print(i, p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c7c157e",
   "metadata": {},
   "source": [
    "#### Generate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "369b4839",
   "metadata": {},
   "outputs": [],
   "source": [
    "class retrieval_generator:\n",
    "    def __init__(self, K=4):\n",
    "        self.src_mask = torch.ones(BATCH_SIZE, ENC_SEQ_LEN).bool()\n",
    "        self.tgt_mask = torch.ones(BATCH_SIZE, DEC_SEQ_LEN+1).bool()\n",
    "        self.K = K\n",
    "    \n",
    "    def __next__(self):\n",
    "        X = np.zeros([BATCH_SIZE, ENC_SEQ_LEN]).astype(int)\n",
    "        y = np.zeros([BATCH_SIZE, DEC_SEQ_LEN+1]).astype(int)\n",
    "        y[:, 0] = 10\n",
    "        for i in range(BATCH_SIZE):\n",
    "            X[i], y[i, 1:] = create_sequence(one_hot=False, K=self.K)\n",
    "\n",
    "\n",
    "        return torch.tensor(X), torch.tensor(y), self.src_mask, self.tgt_mask         \n",
    "\n",
    "\n",
    "# generator = retrieval_generator(4)\n",
    "# generate_data(generator, task_name='retrieval_4', train_size=TRAIN_SIZE, test_size=TEST_SIZE, val_size=VAL_SIZE)\n",
    "# ENC_SEQ_LEN = 31\n",
    "# generator = retrieval_generator(15)\n",
    "# generate_data(generator, task_name='retrieval_15', train_size=TRAIN_SIZE, test_size=TEST_SIZE, val_size=VAL_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e0665820",
   "metadata": {},
   "outputs": [],
   "source": [
    "# s,t, _, _ = next(generator)\n",
    "# s[0], t[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae2fa27",
   "metadata": {},
   "source": [
    "### Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25934197",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Init number  0\n",
      "{'dec_max_seq_len': 1, 'dec_num_tokens': 11, 'depth,heads': (1, 1), 'dim': 20, 'enc_max_seq_len': 3, 'enc_num_memory_tokens': 0, 'enc_num_tokens': 37, 'return_tgt_loss': True, 'tie_token_embeds': True}\n",
      "0.0 %\n",
      "input:   tensor([15,  2, 32,  1, 19,  3, 24,  0, 19], device='cuda:1')\n",
      "predicted output:   tensor([[4]], device='cuda:1')\n",
      "correct output:   tensor([3], device='cuda:1')\n",
      "accuracy: 0.34346336126327515\n",
      "input:   tensor([15,  2, 32,  1, 19,  3, 24,  0, 19], device='cuda:1')\n",
      "predicted output:   tensor([[3]], device='cuda:1')\n",
      "correct output:   tensor([3], device='cuda:1')\n",
      "accuracy: 0.3245662450790405\n",
      "input:   tensor([15,  2, 32,  1, 19,  3, 24,  0, 19], device='cuda:1')\n",
      "predicted output:   tensor([[7]], device='cuda:1')\n",
      "correct output:   tensor([3], device='cuda:1')\n",
      "accuracy: 0.33760637044906616\n",
      "input:   tensor([15,  2, 32,  1, 19,  3, 24,  0, 19], device='cuda:1')\n",
      "predicted output:   tensor([[7]], device='cuda:1')\n",
      "correct output:   tensor([3], device='cuda:1')\n",
      "accuracy: 0.3414742052555084\n",
      "input:   tensor([15,  2, 32,  1, 19,  3, 24,  0, 19], device='cuda:1')\n",
      "predicted output:   tensor([[7]], device='cuda:1')\n",
      "correct output:   tensor([3], device='cuda:1')\n",
      "accuracy: 0.3386009633541107\n",
      "input:   tensor([15,  2, 32,  1, 19,  3, 24,  0, 19], device='cuda:1')\n",
      "predicted output:   tensor([[4]], device='cuda:1')\n",
      "correct output:   tensor([3], device='cuda:1')\n",
      "accuracy: 0.34180572628974915\n",
      "input:   tensor([15,  2, 32,  1, 19,  3, 24,  0, 19], device='cuda:1')\n",
      "predicted output:   tensor([[7]], device='cuda:1')\n",
      "correct output:   tensor([3], device='cuda:1')\n",
      "accuracy: 0.31119459867477417\n",
      "input:   tensor([15,  2, 32,  1, 19,  3, 24,  0, 19], device='cuda:1')\n",
      "predicted output:   tensor([[7]], device='cuda:1')\n",
      "correct output:   tensor([3], device='cuda:1')\n",
      "accuracy: 0.3361697494983673\n",
      "input:   tensor([15,  2, 32,  1, 19,  3, 24,  0, 19], device='cuda:1')\n",
      "predicted output:   tensor([[2]], device='cuda:1')\n",
      "correct output:   tensor([3], device='cuda:1')\n",
      "accuracy: 0.337385356426239\n",
      "Total time:  3402.23805975914\n",
      "{'dec_max_seq_len': 1, 'dec_num_tokens': 11, 'depth,heads': (1, 1), 'dim': 20, 'enc_max_seq_len': 3, 'enc_num_memory_tokens': 2, 'enc_num_tokens': 37, 'return_tgt_loss': True, 'tie_token_embeds': True}\n",
      "1.3888888888888888 %\n",
      "input:   tensor([15,  2, 32,  1, 19,  3, 24,  0, 19], device='cuda:1')\n",
      "predicted output:   tensor([[2]], device='cuda:1')\n",
      "correct output:   tensor([3], device='cuda:1')\n",
      "accuracy: 0.49243009090423584\n"
     ]
    }
   ],
   "source": [
    "gen_train = data_loader(task_name=f'{TASK_NAME}_train', batch_size=BATCH_SIZE, enc_seq_len=INPUT_LEN, dec_seq_len=DEC_SEQ_LEN)\n",
    "gen_val = data_loader(task_name=f'{TASK_NAME}_val', batch_size=VAL_SIZE, enc_seq_len=INPUT_LEN, dec_seq_len=DEC_SEQ_LEN)\n",
    "gen_test = data_loader(task_name=f'{TASK_NAME}_test', batch_size=TEST_SIZE, enc_seq_len=INPUT_LEN, dec_seq_len=DEC_SEQ_LEN)\n",
    "\n",
    "\n",
    "t = time.time()\n",
    "with torch.cuda.device(1):\n",
    "    for init_num in range(NUM_INITS):\n",
    "        print('\\n\\n\\nInit number ', init_num)\n",
    "        for i, param in enumerate(list(model_parameters)):\n",
    "            print(param)\n",
    "            param['enc_depth'], param['enc_heads'] = param['depth,heads']\n",
    "            param['dec_depth'], param['dec_heads'] = param['depth,heads']\n",
    "            param.pop('depth,heads')\n",
    "\n",
    "            print(i / len(model_parameters) * 100, '%')\n",
    "            model = XTransformer(**param).cuda()\n",
    "\n",
    "            model_name = f\"{TASK_NAME}_dim{param['dim']}d{param['enc_depth']}h{param['enc_heads']}M{param['enc_num_memory_tokens']}l{param['enc_max_seq_len']}_v{init_num}\"\n",
    "\n",
    "            optim = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "            train_validate_model(model, \n",
    "                                train_generator=gen_train, \n",
    "                                val_generator=gen_val, \n",
    "                                optim=optim, \n",
    "                                model_name=model_name, \n",
    "                                dec_seq_len=DEC_SEQ_LEN,\n",
    "                                num_batches=NUM_BATCHES,\n",
    "                                generate_every=GENERATE_EVERY)\n",
    "            test_model(model, gen_test, model_name, param, TASK_NAME, tag=TAG, dec_seq_len=param['dec_max_seq_len'])\n",
    "            print('Total time: ', time.time() - t)\n",
    "            t = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af6a937e",
   "metadata": {},
   "source": [
    "### Test!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fff01ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "TASK_NAME = 'retrieval_15'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "84aec64c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dec_max_seq_len': 1, 'dec_num_tokens': 11, 'depth,heads': (1, 1), 'dim': 20, 'enc_max_seq_len': 5, 'enc_num_memory_tokens': 32, 'enc_num_tokens': 37, 'return_tgt_loss': True, 'tie_token_embeds': True}\n",
      "5 32\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 37, 20])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init_num = 0\n",
    "\n",
    "gen_train = data_loader(task_name=f'{TASK_NAME}_train', batch_size=BATCH_SIZE, enc_seq_len=ENC_SEQ_LEN, dec_seq_len=DEC_SEQ_LEN)\n",
    "gen_val = data_loader(task_name=f'{TASK_NAME}_val', batch_size=VAL_SIZE, enc_seq_len=ENC_SEQ_LEN, dec_seq_len=DEC_SEQ_LEN)\n",
    "gen_test = data_loader(task_name=f'{TASK_NAME}_test', batch_size=TEST_SIZE, enc_seq_len=ENC_SEQ_LEN, dec_seq_len=DEC_SEQ_LEN)\n",
    "\n",
    "\n",
    "param = list(model_parameters)[5]\n",
    "print(param)\n",
    "param['enc_depth'], param['enc_heads'] = param['depth,heads']\n",
    "param['dec_depth'], param['dec_heads'] = param['depth,heads']\n",
    "param.pop('depth,heads')\n",
    "\n",
    "model = XTransformer(**param).cuda()\n",
    "\n",
    "model_name = f\"{TASK_NAME}_dim{param['dim']}d{param['enc_depth']}h{param['enc_heads']}M{param['enc_num_memory_tokens']}l{param['enc_max_seq_len']}_v{init_num}\"\n",
    "\n",
    "optim = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "src, tgt, _, _ = next(gen_train)\n",
    "\n",
    "print(model.encoder.max_seq_len, model.encoder.num_memory_tokens)\n",
    "model.encoder(torch.cat((src, src)), return_embeddings=True).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d2702fa6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([36,  9, 23,  9, 18,  7, 21,  4, 29,  3, 14,  6, 31,  4, 33,  2, 12,  0,\n",
       "         35,  4, 20,  0, 28,  9, 15,  6, 16,  5, 17,  7, 28], device='cuda:0'),\n",
       " tensor([10,  9], device='cuda:0'))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src[0], tgt[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
